A nossa equipa irá realizar uma imersão completa na infraestrutura existente com o objetivo de identificar melhorias tangíveis ao longo de cinco eixos prioritários: 
Versionamento e registo de experiments
Automatização de pipelines
Integração CI/CD
Detecção de data & model drift
Arquitetura de dados para deployment de modelos
Mecanismos de ética e explicabilidade.
No eixo do versionamento e registo de experiments, iremos rever a implementação atual de MLflow no processo de MLOps Stacks da Databricks, analisando a estrutura de tracking, tagging e gestão de runs e modelos, focando adicionalmente na inclusão de uma nomenclatura consistente. Propomos a introdução de uma camada padronizada de experiment templates adaptada às necessidades do CA, garantindo reprodutibilidade e consistência entre equipas. Também sugerimos integrar diretamente o MLflow Registry com os ciclos de pull requests em Azure DevOps, promovendo o controlo de qualidade e rastreabilidade dos modelos de forma automatizada. Adicionalmente, serão estudadas possibilidades alternativas como Azure Container Registry para situações onde o produto desenvolvido tenha como requisito de infraestrutura a criação de Containers. Finalmente, integraremos estes processos com o serviço de Azure API Management para garantir um serviço centralizado de gestão de APIs. Analisaremos a inclusão destes princípios dentro do fluxo actual desenvolvido, priorizando a automação destes processos através de templates. 
Relativamente à automatização de pipelines, será efetuada uma auditoria técnica aos fluxos atuais de ingestão, pré-processamento, treino, avaliação e deployment de modelos. A nossa proposta inclui a evolução destes pipelines para pipelines declarativos e reutilizáveis utilizando Databricks Workflows e Azure ML Pipelines, com o objetivo de modularizar as tarefas e garantir a escalabilidade. Iremos introduzir templates com boas práticas como validação de esquemas (data contracts), data drift checks e testes automatizados (unit/integration tests) para componentes críticos.
Ao nível da integração com pipelines de CI/CD, iremos realizar um mapeamento da integração entre Azure DevOps e os ambientes de treino e serving. Iremos propor e implementar fluxos GitOps para modelos, onde qualquer alteração ao código, dados ou parâmetros desencadeia automaticamente um ciclo de validação e promoção de modelos, alinhado com as melhores práticas de controlo de versões. Para isso, será configurada uma arquitetura com environments as code (Terraform), validações automatizadas e gates manuais para aprovação em ambientes sensíveis (e.g. produção).
Para a Detecção de Data & Model Drift, propomos a implementação de sistemas de monitorização automatizada que alertem de forma proativa para desvios nas distribuições de dados ou no desempenho dos modelos. Para a detecção de data drift, sugerimos o uso de métodos como por exemplo, o Kullback-Leibler Divergence Plot e KS (Kolmogorov-Smirnov) Test plot, que permitem identificar mudanças significativas nas distribuições de características em relação aos dados de treino. A introdução de Bollinger Bands nas métricas-chave também pode ser uma solução eficiente para sinalizar desvios fora do intervalo esperado. No caso de model drift, propomos a utilização de métricas standard, como a performance degradation over time, calculando a diferença entre o desempenho do modelo em produção e os dados mais recentes, bem como a aplicação de técnicas de drift detection baseadas em comparação de previsões com variáveis de controle, permitindo detectar se o modelo perdeu a capacidade de generalizar. A integração dessas técnicas em um sistema de alerta automatizado permitirá respostas rápidas e ágeis a essas mudanças, minimizando impactos negativos no desempenho e na confiabilidade dos modelos.
No que respeita à Arquitetura de Dados para Deployment de Modelos, propomos a implementação de uma feature store robusta, centralizando e versionando as características utilizadas pelos modelos. Além disso, sugerimos a criação de uma inference database (DB), que armazena dados pré-processados e otimizados para servir modelos de forma eficiente, reduzindo o tempo de latência e evitando recalculações desnecessárias. Esta arquitetura permitirá o acesso rápido a features historicamente relevantes para a inferência, alinhando-se com práticas de real-time data pipelines. A integração de um sistema de data versioning nesse fluxo garante que a consistência dos dados seja mantida, permitindo o reuso de versões específicas de dados e resultados de inferência, essencial para modelos que requerem explicabilidade e conformidade regulatória. Este design inteligente de dados não só garante eficiência no deployment de modelos, mas também permite escalabilidade e controle de qualidade contínuo nos processos de inferência. 
Por fim, no domínio da ética e conformidade, será proposta uma camada transversal de explicabilidade e model governance. Será avaliada a utilização de bibliotecas como SHAP, LIME, fairlearn ou semelhantes nos pipelines de avaliação, a ser implementado use case a use case, mas também iremos sugerir a criação de um repositório central de relatórios de model cards, promovendo a documentação e transparência dos modelos em conformidade com o AI Act. Esta camada será integrada com dashboards de monitorização para acompanhamento contínuo de métricas como bias, drift e impacto operacional.